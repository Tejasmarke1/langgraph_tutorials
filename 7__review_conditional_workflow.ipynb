{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bd7c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START, END\n",
    "from typing import TypedDict,List ,Annotated,Literal\n",
    "from pydantic import Field,BaseModel\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a46be9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33af7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8740f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentinementSchema(BaseModel):\n",
    "    sentiment:Literal['positive','negative']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20099bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68096088",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmodel=model.with_structured_output(SentinementSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c42e83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmodel2=model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d58cd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 14.087626236s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:3047\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   3046\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3047\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m   3048\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest,\n\u001b[0;32m   3049\u001b[0m     )\n\u001b[0;32m   3050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\google\\genai\\models.py:5474\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   5473\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5474\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_config\u001b[49m\n\u001b[0;32m   5476\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5478\u001b[0m function_map \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_function_map(parsed_config)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\google\\genai\\models.py:4214\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   4212\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[1;32m-> 4214\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4215\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[0;32m   4216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m   4219\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m ):\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\google\\genai\\_api_client.py:1386\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m   1383\u001b[0m http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m   1384\u001b[0m     http_method, path, request_dict, http_options\n\u001b[0;32m   1385\u001b[0m )\n\u001b[1;32m-> 1386\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1388\u001b[0m     response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1389\u001b[0m )\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\google\\genai\\_api_client.py:1220\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[0;32m   1219\u001b[0m     retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_kwargs)\n\u001b[1;32m-> 1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\tenacity\\__init__.py:471\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 471\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\tenacity\\__init__.py:372\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 372\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\tenacity\\__init__.py:414\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\tenacity\\__init__.py:474\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 474\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\google\\genai\\_api_client.py:1199\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m   1192\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   1193\u001b[0m     method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   1194\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1197\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m   1198\u001b[0m )\n\u001b[1;32m-> 1199\u001b[0m \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m   1201\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m   1202\u001b[0m )\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\google\\genai\\errors.py:134\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m    132\u001b[0m   response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mbody_segments[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\google\\genai\\errors.py:159\u001b[0m, in \u001b[0;36mAPIError.raise_error\u001b[1;34m(cls, status_code, response_json, response)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m--> 159\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n",
      "\u001b[1;31mClientError\u001b[0m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 14.087626236s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis very bad moobile\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m response\u001b[38;5;241m=\u001b[39m\u001b[43mstmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39msentiment)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3151\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3151\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3152\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3153\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5691\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5684\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5686\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5689\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5690\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5692\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5694\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5695\u001b[0m     )\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:2535\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[1;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[0;32m   2532\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.code_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2533\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 2535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[0;32m    397\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    400\u001b[0m         cast(\n\u001b[0;32m    401\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 402\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    403\u001b[0m                 [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    404\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    405\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    406\u001b[0m                 tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    407\u001b[0m                 metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    408\u001b[0m                 run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    409\u001b[0m                 run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    410\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    411\u001b[0m             )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    412\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m    413\u001b[0m     )\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1119\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1120\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    930\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 931\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    932\u001b[0m                 m,\n\u001b[0;32m    933\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    934\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    936\u001b[0m             )\n\u001b[0;32m    937\u001b[0m         )\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    939\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1233\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1234\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1235\u001b[0m     )\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:3051\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   3047\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m   3048\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest,\n\u001b[0;32m   3049\u001b[0m     )\n\u001b[0;32m   3050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3051\u001b[0m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[0m, in \u001b[0;36m_handle_client_error\u001b[1;34m(e, request)\u001b[0m\n\u001b[0;32m    143\u001b[0m model_name \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError calling model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 14.087626236s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}"
     ]
    }
   ],
   "source": [
    "prompt=f\"this very bad moobile\"\n",
    "response=stmodel.invoke(prompt)\n",
    "print(response.sentiment)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "    review:str\n",
    "    sentiment:Literal['positive','negative']\n",
    "    response:str\n",
    "    diagnosis:dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ffea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state:ReviewState):\n",
    "    prompt = f\"for the following reviwe find the sentiment of the reviwe\\n {state['review']}\"\n",
    "    sentiment=stmodel.invoke(prompt)\n",
    "    \n",
    "    return {'sentiment':sentiment}\n",
    "\n",
    "\n",
    "def check_sentiment(state:ReviewState)-> Literal['positive_response','run_diagnosis']:\n",
    "    sentiment=state['sentiment']\n",
    "    if sentiment=='positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_response(state:ReviewState):\n",
    "    prompt=f\"\"\"write a warm thank you message in response to this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "    also ask user to kindly toleave the feedback on our website\"\"\"\n",
    "    \n",
    "    response=model.invoke(prompt).content\n",
    "    \n",
    "    return {'response':response}\n",
    "\n",
    "\n",
    "\n",
    "def run_diagnosis(state:ReviewState):\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "    \"\"\"\n",
    "    response=stmodel2.invoke(prompt)\n",
    "    \n",
    "    return {'diagnosis': response.model_dump()}\n",
    "\n",
    "\n",
    "def negative_response(state:ReviewState):\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "    The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "    Write an empathetic, helpful resolution message.\n",
    "    \"\"\"\n",
    "    response=model.invoke(prompt).content\n",
    "    \n",
    "    return {'response':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbe267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAGwCAIAAAAiwVUCAAAQAElEQVR4nOydBWAURxfHZ+8u7kCMKBaguBYrUqBoKU7xIkUrWAUrLsX7QaFFWty9QPECLRR3KxYgBAKEuF/u9nt7G4675JIQcjn9/5oee7Ozu3Ozb//75s3srIzneQYAAKaBjAEAgMkASQIAmBCQJACACQFJAgCYEJAkAIAJAUkCAJgQkCQrQqFQnD8YHfEoJSkhnVdI5GlKSuQkHK/kOQnjhW9MIuGUSl6VnpEi5mF8xnARTlgUExnjOTFVIuWUCp62zciVkZNTb8MxpjnchL5Tmngg9RHFZcYx2pU6p8xGwjjezp4r7Gtbro67l789AxYNh3FJ1sCuX8MjQlPkabxMxuycJFIZk0ll6WlvpOeN0EgZr2AssySp1oqWwr1WHI1EiZR0RKVB4ndt8RI2eZ34eo+qP2XWAwn7UCreZJTZcEpeKU9VJCXwlE0iYa6esgYdiwSUdGbAEoEkWTgbZj+KipA7OEuKl3dq2MmbmTkXj0ZdPxUXF5Vu5yDp8LVvIS8HBiwLSJLFcuGvqLP7ohzdZG0H+7gVtrT2zvaFT54+SPEpZtvxq0AGLAhIkmWybWHYy7C0pj08S1R0ZZbL8nH3KJ7Vf1oJBiwFSJIF8u++lzdOxfWfahUX6o7FYbEv0j+bWIwBiwCSZGlsnv+YQi39pxRnVsPOpY+fh6YNnFGSAfNHwoAFcXDN09hIuVXpEdF2QKB3kP3KSaEMmD+QJMshLjb17uWkz60ysNJ2kH96Gr/vt6cMmDmQJMth449PSlR0YtZKt7GBD64lMWDmQJIshLMHXslT+ea9fZm14ugo8/C2WffjIwbMGUiShXD5r+igMtY+brBVf6/oCDkD5gwkyRKIjkxJS2WtP/dj1o17EQdbB27vCkSUzBhIkiXwz45Xdk4cMyybN2+eMGECyzvff//9rl27WMHgV8Lh6f1kBswWSJIl8PJJamFfW2ZYbt68yd6Jd97wbahU312ehqF2ZgwkyRJITVb6FS+oQNLDhw/Jr2natGmTJk1GjBhx+fJlShwwYMCePXv27t1bvXr127dvU8qmTZu++OKLhg0bNmvWbPTo0U+ePBE337hxI6UcO3asZs2ac+bMofxPnz6dMmUK5WQFgH8pR55nzx6i681cgSRZAkoF8y/tyAqAtLQ0Uh+pVLpw4cIlS5bIZLLhw4enpKQsXbq0fPnyrVq1On/+fJkyZUinZs+eXalSJRKdSZMmRUVFjRs3TtyDra1tYmLi1q1bJ0+e3Llz55MnT1Li+PHjSaRYwSC1YWF3IEnmCqZwswTILyhUxI4VAI8ePSJ96dq1K+kOfZ05c+bFixfT09MzZatQoQKFlgIDA0mz6KtcLiflio2NdXNz4ziOJKx37941atSgVampqayA4ThJcgLabuYKJMkSUE3SyAoCUhkPD4+JEye2bNmyWrVq5AdRyytrNnKjqKU2d+7c69evk08kJpKWkSSJy+XKlWOGg2dKSJK5goabhRAblcYKADs7u2XLltWrV2/9+vX9+vVr27btvn37smY7fvw4hZnee+89ynzu3LlFixZlykDNN2YolOm8raOh+x+BvoAkWQLkIoUXWM93cHDwsGHDKJg9b968kiVL/vDDD2I8W5MdO3ZUrlx56NChISEh1FKLj49nxkORzooGY4pucwWSZAnYOkie3C0QSaLutt27d9OCvb19/fr1f/zxR4oW3bp1K1M2Cht5eXmpvx49epQZiVfPUugz6D0XBswTSJIl4F5E9jysQMLGpDXUU7ZgwYKwsDAKdf/+++8U26aIEq0KCAigyBE10yhmRM7R6dOnqfeN1q5bt07c9tmzZ1l3SC1BEi91ZqZvzh2M4qQMmC+QJEugZvPCqYlKVgCQ+owZM+bPP/9s165dhw4dLl269MsvvxQvLszH1L59e2qjUWPt7t27Q4YMqVOnDoWTateuHRERMWnSJIorffXVV/v378+6z759+5KQjRw5MjlZ/57d49tJXv42DJgtmFXSQlg86l7pai6Nu5r9O0jyyaLh9/pPC7Z3RFeyuQIvyUIIqery33ljBpVNgY1zHts5SqBHZg1OnoXQpJv3fxfiT+5+UbeNl84Mo0eP/vfff3WuopiOOMQxKxMnTiygJz+I7PasUCjIec+uSIcOHbKx0d00iwxP6zyqKAPmDBpulsONM7HHNr0cOk/3rPgUuMkunJyDJDk4OGS3Kv/kMFYghyK5uOjuTVs58YG9i/TTkUEMmDOQJItiy4JHyQnKXuOs7g1Cx7e/vH02duBMvKTE7EEsyaLoNCxIkc42zrWuyV7vX4m9/g/0yEKAl2SBbF/4OIF8pdHBzAo4f/jV2f3RQ+ZAjywESJJlsmryQ3l6ev/JFn6hbpjzMDoiHXpkSUCSLJY/loY9up0aEOLwySALnJP79L6X5w/H2juy/lOhRxYFJMmSiYlM3Tr/SUoy7xVgU6tlocDSZv/kV0qy/MjaFw9vJ5PZVmnomt2IB2C+QJIsn7uXYv/dFxX3SiGRMHsnibOHzMFJamsvVSi0snGcMBWcVMIpVJMNiV/VqzgJr1RknvGDE6Ym0sqZaW/igoBgZ5zmKmGfPK9UJapTVEmcuN+M8si49FRFcrwiKUGRGJtOwXsbOxZSzaVRJ2sfp26pQJKsiMvHox7eTIp7lS5PU9CVL0/VOvWiBEiknFIhStIb2xDEQsp4HaOaMkRJ9SnIDv0jEUVGe3PVau0thRxMKaa+1iD6n1eqtxL2ILMViiW14Vw8ZD7FHD74xJMBiwaSBPTGH3/8ceHChYkTJzIA3hU8UAL0Rg5DrgF4S2BAQG9AkkD+gQEBvQFJAvkHBgT0hlwuz+4ZfQDeEkgS0BvwkkD+gQEBvQFJAvkHMwEAvQFJAvkHkgT0BmJJIP/gngb0BrwkkH9gQEBvQJJA/oEBAb0BSQL5BwYE9AYkCeQfGBDQGwhvg/wDSQJ6A14SyD8wIKA3IEkg/8CAgN6AJIH8AwMCegOxJJB/IElAb8BLAvkHBgT0BiQJ5B8YENAbkCSQf2BAQG9AkkD+gQEBvQFJAvkHBgT0BiQJ5B8YENAbnp6eUqmUAZAPIElAb7x69UoulzMA8gEkCegNarVR240BkA8gSUBvQJJA/oEkAb0BSQL5B5IE9AYkCeQfSBLQG5AkkH8gSUBvQJJA/oEkAb0BSQL5B5IE9AYkCeQfSBLQG5AkkH8gSUBvQJJA/oEkAb0BSQL5B5IE9AYkCeQfSBLQG5AkkH8gSUBvQJJA/oEkAb0BSQL5B5IE9AYkCeQfjud5BkA+aNGixfPnzzVTyKgCAwN37drFAMgjEgZA/vjkk09sbGwkGpC7RIkMgLwDSQL5pUePHv7+/popAQEB7dq1YwDkHUgSyC/Ozs4kQJrvJmnUqJGHhwcDIO9AkoAe6Natm5+fn7hctGjRjh07MgDeCUgS0AMUP+revbudnR0t165d29fXlwHwTqDHzchcOh4Z+SQ966uGOAnjldopHHVl0X/CgvqkSTimzHICOTqtjNdOYdmd5qyraP+0W4UyS05O+MxqL0J+xhQ8O33mtDxNXrVqVScnJ/amnLzqIFl2JVgex7ItlY61b364sFL3tlRyXqOQmnWVXYqOnUiVzm429dp4MmBwIElG4/HthD9XPlfyvI1Mkpaa+SxIJZlFgUSK8cL50ryoOE7nGcysM2o5y5qPZdU+ibBbpSJzdpUI6DickE47UQjLquJxr/fD8UpepxoKh+A5ZTa2J/xApkM5xB2ynBVWItSIMidJypDDHJDKhNXyNBb0nv3H/f0ZMCCQJOMQfj9hx+KI6k0KlatTiAGTJD4qedcv4RU/cK/buggDhgKSZATSktOWjnvc+4eSDJg8m+bcDyzt+FEPRMcMBMLbRmDboqfunniUxzwoXdP1/rVEBgwFJMkIxEcrfIMdGDAHKtf3pDBZ1MtkBgwCJMkIKNJ4Gzt4SWaDUsFSEhgwDLgwjIBCySnTEcIzI3gpx4BhgCQBAEwISBIAwISAJBkBiYTnUPHmBMfziLoaCFwZRkCp5HhMvmhO8BynZMAgQJIAACYEJAkAYEJAkoyA8CyoBL3KZgWH82UgIElGQJhaQ4lxSWYDz3MMp8tQQJKMAJcxRQYwDziOZ9AkQwFJMgIqOUIPDgA6gCQZAWq0CW0BAEAWMADM2vmkXePVa5Yzy6JPv84LfprJ9Aa13HClGAhUtBGgYCln1B63dh2aPn0WLi536dyzYoUqrOCZNPn7fX+a6ftvyadFQ9tAQJKMAHW48cbrcYuIeBYTE63+2q3rZ5UrV2MFz3//3WQA5AZiSebB6TMnN21affu/G4UKFSlfvtKA/l8WLixMCB0V9WrxknnXb1xJSUmpUaN2rx79AwKCKD009H7f/l0W/7xq/frf/zl5zNPTq1HDjwZ8/uXVa5dGjBxEGbr3+KRu3QZTJ8+lhluH9l179ey/Y+fmNWuXz5q5aOz44a9eRQYFFRs5fCyJ14yZP6Qr0mtUrz1i+Bh3d493OKhUKm3UuDplmD1nypJf5v+x61gOv7Rt+yZ9PhsUGxuzavVSBwcHOu4XQ0eJP5agNuaBg3siI194eflUrlRt+LDREolwW3348MHMHyc8ehxauXJ1Ko/mDrMrLTBN4CUZAWEQgCQPNX/n7u3RY76uUqXGyt+2fvXlt/fv3/lx1kRKVygUw0cOvHzlwvBhY35bvsnDvdCQob3Dnz6hVTY2NvQ5d97Uxo2bH9z/79jRUzdvWfvXsUNVKlefMW0BrVq3dhfpkeZRaJOEhPiVq3+dM2sxqYZcLp8+84c/9+9evmzjujW7rl2/vGnzmnc7KCXu33eSPr8ZNT5nPRJ3QuJLQrNzx5FVv2+j465c9au46veVv+zctXnwwGFbtxzo13fIseOHtmxdR+lU1O9Gf+np6U31M/DzrzZuWk2SKm6SQ2nzCLojDAQkyQgIo1yUeYhNXL922d7evkf3vt7ePu/XrDN39pKuXT+j9GvXLj9+/HDM6CmUWKhQ4cGDhrm6uW/btl69YYP6TRo2aEIXeaVKVYv6+t25cyvnA9G13bvXAHIiyD15v2bdZ8/CyQ2hg9LOySUhKSyIg2bFzy+AfqyLsws5R+QliXuIT4jfsHFVzx7969VrSKvoEO3adlm7bgWV+cTfR1+8eD50yEgqanBwcVJt0lZxV7mW9m3goUcGBJJkBpSvUJkaHaPHDiOn4El4mJubOzk7lE4eBF35VavUELNxHEfCceXqRfWGISFl1cvOzi7qCzUHgoOKiwuOjo4eHoXoMha/Ojg4JiQmFNBBM6G5BxcX10TVccPCHpH6lC1bXjNbQkJCeHgY/ZFk+/hkvESEhMzLy1tczrW0b4P4tkoGDAJiSUZAJmMSWR5uvCGlysyc8b8TJ44sXbZw8ZL51arW/Kz3QIoo0dVOV6kYplEjhntEJJI833I0h5XrHGJeEAfNoQxqoqKEtpi9nb06hVSSoVDPUwAAEABJREFUPpOTk+LiYsVlNXavs+VaWmBqQJKMQHo6y+vc29TuoD+K+164cGbb9g1jxg7bvu0QuQPUwpo2db5mTqlEygoSoxyUcHJyps/klDdvCklKEt5lRPF+V1c3EibNzOIqI5YWvDOQJDPg8uULqWmpJElFing2a9bax6fosBEDIp4/K1EiJDk5mfqe/IpmvCT66bNwd7eCdQGMclDxuNRzd+PGlbJlyokpt25dp6AS9ev5ePtSw/bBg3vFiwtv67x3705k5Et9lxbhJAOBWJIRUPW45cHEqQN74qRv/9iznbrkb966vn3HRtImug6pBVezZp05c6Y8fx5BveY7d20ZNLjn/v27c95bQGAwfR47doh2xfLOux3Uzs6OtOP8+dOXLp9PT3+XKTVdXVybNmm5dt1vp06diIuPO3hw746dmzp27E7txDp1Gtja2s6ZN5WEicRo8tTR5Dflp7RZgB4ZDnhJRkDV45aHhlvnTj1IjBb9PGfe/Ol07X3YqNn8eUtlMuHcUY/+7j+20UV48+Y16ilr0qRF+/af5rw38heaN/uYOtTLl6s0f96vLO+8w0GJ7t360kHPnju1Yf0e8m5Y3qE+NRKgKdPGkKgVLerfrWufrp/2ZkIQ3Xn6tAVLl/6vdZsGFOce8PlXh4/8mc/SaoPwtuHgeB51bWiWjLr/Xh23qo2LMGAOrJp4t9PX/t54QbFBgJdkBBRKxisYACArkCQjILw0yVqDeNeuXabuwuzWrl2z083NnZkiCCcZCEiSERBemmStD5ZXqFB56dJsB0+bqB7xUCTDAUkyAhIp46TW29fp61OUmRecar50YBAgSUaAAknoVQBAJ5AkIyCR4B08AOgGkmQEVD1u8JIA0AEkyQhwEp7hKSvzgcfc2wYEkmQEOF4QJWAucJh724BAkoyAkmdKWDgAuoAkGQGJhJNY8SAAAHIAkmQEeAJuEgC6gCQZAZ7HyDsAdANJMgK2thyTwksyG6RSDrcQgwFJMgIyOz4mMo0BcyAhKk2hZD7FMDOJgUCQ1QgEhDhFPk5lwBw4teeFkxsuE8OBujYCTbv7UEBp15JQBkybF+EJzx+l9BqHt+MaDswqaTTW/RianKAILOPsHeQkzTImgON0hMC1JsngdE++qs6TdQ/qVZSu4yG71zvUXJt1Wg7VXjntLbSOwKtudHz2W+kskvbeMh+WviiF8YpcrjmzVpJSGH3NcXy2ebIiYXzUy9TQG/HxUelDZpdkwIBAkozJnuXhT0OTFXJGf2bDO00elN1Gep+J6B12mFWgJVJOKmMuRaTdRgUzYFggSWbDf//9N2bMmAkTJlSsWJGBvBMbG0sVWKdOne7duzNgqkCSTJ3jx49v2rRp8eLFMTEx7u6mOQmsOREZGVmkSJG5c+f6+/t36dKFARMD4W3TJSIigj5Pnjw5bJgwWTX0SC+QHtHngAEDHj16dPfuXSa8GjeJAZMBXpIpcurUqREjRmzYsKFYsWIMFBhk/BT4/uCDD/r27dunTx8GTAB4SSbEw4cPd+3aRQs2NjZ///039Kig4VRhbapqasTRwsWLF+/cucOAUYEkmQrh4eEjR44MDAyk5Ro1apAqMWAomjZtSp/e3t7Ue3Ds2DEGjAcabkbm33///fXXX1euXJmQkODs7MyAsXn27Jmvr+/06dOrVavWrFkzBgwLvCSj8fjxY/o8c+bMd999x1QvtmfABCA9os9evXpRX2dcXFxycjIDBgSSZAQuXbpUq1YtsaOHetPKli3LgIlB0SVylOg+kZ6eTvHvgwcPMmAQIEmGIzQ0dNOmTUyY7EJKIdUyZcowYNpIJBIXF5cDBw6QMNHX06dPv3z5koGCBJJkCMigY2Jivvnmm+DgYPpasWJFRK/NCEdHx5YtW9ICyVPPnj1v3LjBQIGB8HbBcu7cuQULFixfvpw8I1tbWwbMn4iICB8fn6lTp7Zq1apKlSoM6BV4SQWFOMLl6tWr48ePd3BwgB5ZDKRH9Nm6detly5Yx1aNzDOgPSJL+uX79eo0aNcTodb9+/RAzskgqV668ePFippKkNm3aUJcFA/oAkqQ37t+/v2LFCiZMrW1LXftksgxYAYGBgUuWLHn+/DlTjTJDJCSfQJL0QEpKSmpq6ujRo0uXLk1fQ0JCqKeGAavBz8+vefPmtEBmQA6y+Lw0eDdw5eQLcte7d+8eHx8vk8k2b95cr149BqyYhg0bnj9/noyBlqdNmxYWFsZAHoEkvSMUMKLPmzdvUvTa09OTOtQYACrE+U+qV68+a9YsWoiJiWHgrYEk5Zl79+7VrFkzLi6OlslFQvQa6KRZs2YLFy5kqiBj3759xeeHQK5Akt4WMqz//e9/tEBuOUUx69SpwwB4C6pVq/b111+Lg0Ko34OBHIEk5U5CQgJ9Tpw4sXz58rQQHByMZhrIE5UqVWrSpAlTTYnVuHFjzGOZAxi9nRPXrl2bPn36jBkzxAdBAMg/FFoS49+//fZb//79HR0dGdAAXpJuqN+EPh88eDBp0iToEdAj7u7uzirc3NzGjh1LKWJcEojAS8rMkydP2rZtO3fu3AYNGjAACp69e/ceOXKEum49PDyY1QNJyoz4UCUDwIAcP36cWnN169ZlVg8ablr07t0boWtgeMglhx6JQJK0iI2NTUlJYQAYnJ49e+L9KISMAQ1WrFhBQUcGgMFRKBSIojDEkgAwEUiSEDRgaLhl4quvvrp37x4DwOBAj0QgSVrgJTnAWCCWJIJYkhbz58/H+9SAUUAsSQSxJABMAsSSRNBw02LcuHEXL15kABgc6JEIJEmLhISExMREBoDBQSxJBLEkLSZNmmRvb88AMDiIJYkglgSASYBYkggablrMmjXr2LFjDACDAz0SgSRpkZSUFB8fzwAwOIgliSCWpMXIkSPFGf8AMDCIJYkglgSASYBYkggablosW7Zs586dDACDAz0SgZck8OGHH6rf/8dxQp0Qvr6++/btYwAYBIoljR8/PiQkhFk38JIE6tatS0okUaFeEN/yDoBhQCxJBF6SwP3794cNG/bs2TN1StGiRZcuXYpJuIHBQCxJBF6SQIkSJTK9vZa+Qo+AIYEeiUCSMujVq5e/v7+47Onp2bVrVwaAAcG4JBFIUgZ+fn7169cXl6tXrx4UFMQAMCCIJYkUYCzp4bVYBa817JBjLNPBXqfwqsWc82TAM56jbrEs2XQh7DZTTu71wbJuHhcfv/jnn1PTUvv17evvH8DeCe71gbMWmGVf5px/Ti4/VpkeUNrB1sGWAXMGsSSRApGkVVNC46MVUhlTyLUPlt2l9UaRzACqMC5Ppc3rr8tjfqpnJc/sHbhPBhUt4ufAADBn9C9Jv35/z8PbtmFXHwfctw3I39ufPriW9NmEIGc3GwbMEIxLEtFzLOnX7+6Vrubcom8g9MjAfNC+aO8JJVdOepSWnMaAGYJYkog+vaS9K8KfP0rtNLI4A0Zi3/KwtFRFzzHBDJgbiCWJ6NNLinicUqgoWg3GpFhlx/iodAbMEOiRiD4lSZnObB3tGDAeRfxc4PubKRiXJKLPuYHkqTyfpmDAeHDpjMcZME8QSxLBdGUAmARr1qxB241BkgAwEaBHIvqMJQnzenDmM+QRAFMCsSQRfXpJPJrCALwriCWJ6FWSmOppC2Bc4KeaJ4glieg5lsThgjAqPHurx5GBCQI9EtFnLEl4qhaKZFxQ/2YLYkkiaLhZFByq32xBLEkEgwAAMAkQSxLRpyRJpcLLPRgwHjzazmYL9EhEnwoiOJ5KJQPGQ4K2m9mCWJKInp0aE+9x69Ov84KfZtLCgwf3GjWufvXqJWYC6LEwkCPzBbEkEX023ISh22bSanB39+jVs7+Xl0m8FsmkCgOMBWJJIvoevW0mMl+oUOE+nw1ipoEeC4ObrPkCPRLR67ikPD7jJjZYTp/+p2Pn5v0HCO9NGz12GP2pMxw4sIcyJCUl0XLb9k127d66es3yxk1rtm7TYNLk71+9isz1EA8fPhg0uGeLVvVot7duXc90aLGtlJCQ8PvKXwYP7U3ZevRsu3jJ/JSUFDGbUqmcv2BGh07Nunb7ePmKn6motFVU1Ktcy0Pp3Xu2bdaiTs/e7efOm6Z8HWI7febk8BED6UC0dsaPE8RNNAtDmr512/rPB3Rr3rLuwEE9li1fRP48e2sQ2jZfEEsS0fNQyTxhYyNMQbl67fIunXuOHDEu18ybNq2WSCQ7dxxZ9fu2a9cvr1z1a86byOXy70Z/6enpvfK3rQM//2rjptU6VWz7jo3rN6ykMkyftmDgwK+PHT+0avVScdWWrev+2LP9yy+++eWXtQ4Ojit+W0yJElWvYg7lIYHbuWvz4IHDtm450K/vENoh7YfS79y9PXrM11Wq1KDyfPXlt/fv3/lx1sTMhdm+ce263zp26LZx/Z6PP+6wd99OKjZ7e6BJZgtiSSL6bLgpOWo45OGaEF2qGtVrderY/W3y+/kF9OjeV1hydqlRvfadO7dyzn/i76MvXjz/af5yb28hTEMq0KlLi6zZOnfq0aB+46CgYuLX69evnD13auCAr2j5wME99T/4sGGDJrTcvVsfSs+1PPEJ8Rs2rho8aHi9eg3pK2374MHdtetWtG/36fVrl+3t7WkTEjIqUpnS7z0IvZepMFeuXixd+r1mzVrTcutW7Ui/klVO4tsCkzZbEEsS0etQSSXP+DwPAggpVfZtc4a8yeni4pqYmJBz/vDwMJIAHx9f8WvhwkW8vLyzZiN/59z5f2f+OOHe/Tvp6cLE1R4ehZjqrkXtvhbN26hz1v+gsWa/mM7yhIU9Iu+sbNnymtmobUiFKV+hMjUJqQlZvdr7tWvX9/cLqFK5eqbClC9faemyhbNmT65YsQrl8Svqz4B1AD0S0XssieUVW7u3na47r3uPi4ul1pZmip2dfdZsJAGrVi1t1ard2tU7/zpynrwhMT0hMYEcaUdHJ3VONzf3XMsTFSW0De01DiSWITk5KaRUmZkz/leksCcdsWevdqO+GUIeWabNqck27Ovvo2Oifpw1qWOnZtNmjI+MfMmAFYBYkohevSShKazPYIZCma95pF1d3UgINFOSkhIz5aEi/7FnGwkBtZLElISEeHHBUSUl5PKoM0dHv2K54eTkTJ/JKcmZDlqoUBH6fL9mHfqj/rULF85s275hzNhh27cd0tyc2nRUEvojB+3ixbMrVy8l52v61PkMWDqIJYnodahkvqeUtLWx1VQNagSxfODj7UsNJerPEr/eu3cnq8dBipOcnFykiJf4NS0t7dS/J8RlatBRQ+/hw/vqzCdPHWe5UaJECHngN268cX+op8/F2cXT0+vy5QtnzgrRqCJFPClaNHTISAo8RTx/prk5dTKGhgpHDA4u3r79px3ad7137z/21mBST/OFYkmlS5dmVo8+JUmQ+PypPIVgbt++IYrI+Qtn/jl5jOWDOnUa2Nrazpk3lYSJxD/61iMAABAASURBVGjy1NHkN2XKQxkCA4P/3L87/OmT2NiYWXMmVyhfOT4+LjFRUMY6tesfPLT33PnTdPuiXjNKz/Wgri6uTZu0pF6zU6dOxMXHHTy4d8fOTR07dif35/qNKxMnfUtdeDEx0TdvXaeePtIm0k3NzY8c3f/DxG9o29i42NOn//n7n6Ply1Vibw3usuYLYkki+n2gJL+a1PaTzo0/bD5gUPdGjav/+eeuHt2E/qx39madnZ2pX1+Rnt66TYPP+nak1pm6W02T8WOnU+jnsz4de/RqW61qzf79v6Cv7To0eRbxtHevARUqVPn2uy8o9PPoUSjtgfLLZLm8PpPcn7p1GkyZNqZDx4/Wbfi9W9c+3bp+xlRde61atlv085x2HZoOHzGAolTz5y2VybTaziNHjAsOKj52/Ii27RrPnjuF9jNi+FgGrADEkkT0+QLuJd/cDyzjVL+j5TwYQe7VixcR5EaJXzduWr1u3W9/7D7GTJWXT9L2LXv8xYKSDJgb3bp1mzBhAtpu+m248RbWciANIpdt2/aN1KY7+tfBzVvWtmnTkZkwmAbAfEEsSUSfPW4ULuE4g86XdO3a5TEaD6BkYu2anZm67fPKZ70HxMZGHzy4Z9nyhZ6e3u3adlEPETBdEOE2TxBLEtHr6G2lkucNOl9ShQqVly5dn93afOqRyNdffcfMCzhK5gnFksaPHx8SEsKsGz1PTmL4Tmhfn6IMAPMH45JE9CpJDANjAHhH8IybiJ7fUAKZNzo4AWYK9EhE7z1u8JKMCY/ottmCcUkien9pEm7SxkQCQTJbEEsS0esgAGHubVwTxgQmbb4gliSiZy+JR8MNgHcCeiSi11iS4CjhNg3Au4BYkoi+50uCIgHwTiCWJKLnQQAIbwPwbiCWJKJPSZLZSTgbBowIL9X7C4yBgYAeiejTfm1suJREgz7jBjLxKixRhruCeYJYkog+JcmnmN2rZ8kMGI+7V2KdPXCzNUsQSxLh9FsLS8fc9y5m92FnvOrHCCQkJG+bF/7FXMzfZpaQJKHtxvQuScSK8Q9sHfmqTYsElnJjwCDERCWf2ffyRWjawB+LwayBWcMVhK+4duaD+FdKJc9yeelRjk9kCSXLZiw4l/eOvWw3yaYMnK7H9XQmZrOHzKlZC/A2v0JHJQgvptJKkUqFPTk4c30mlmDAbMF8SSJ6f8ZNoMf3xekz9mVamjznjBnXFq/r2uR41X8qHchIeb2svphp+0yK+lo1hCxa22rnVH/lVBnV2Y4dPRr+NLx7j56aevHmcBo7V+9ES6de71ezhBk/77VGaexN+E8rJWO4KadUl1X1I7QrIaMg6t9iI1G4+zgwYOYgliRSIJIk4uZpy8yNdGl0uiTas6j5lRyYOxiXJFKAkmSOpKenZ3qLEQCGAXokgnF1WkCSgLHAuCQRXH5aQJKAsUAsSQSXnxZyudzOzo4BYHAQSxJBw00LeEnAWECPRCBJWkCSgLFALEkEl58WkCRgLBBLEsHlpwUkCRgLxJJEcPlpQeFtGxvM7gGMAPRIBLEkLeAlAWOBWJIILj8tIEnAWCCWJILLTwtIEjAWiCWJ4PLTArEkYCygRyKIJWkBLwkYC8SSRHD5aQFJAsYCsSQRXH5aQJKAsUAsSQSXnxaIJQFjAT0SQSxJC3hJwFggliSCy08LSBIwFoglieDy0wKSBIwFYkkiuPy0gCQBYwE9EkEsSQtIEjAWiCWJ4PLTolSpUuhxA0YhMDCQ4zhm9UCStKDbFDlKDACDM3nyZLTdGCQpE9RqgyQBowA9EkEsSQtIEjAWQ4YMuXDhArN64CVpAUkCRgS2xyBJmYAkAWOxaNEihLcZJCkTkCRgLCQSRFEEUAtaQJKAsRgzZsyRI0eY1QMvSQtIEjAisD0GScoEJAkYi6lTpyKWxCBJmYAkAWOBWJIIakELSBIwFrNmzdq2bRuzeuAlaQFJAkYEtscgSZmAJAFjMWrUKMSSGCQpE5AkYCwQSxJBLWgBSQLGYunSpStWrGBWD7wkLSBJwFhQq00ulzOrB5KkBSQJGIv+/fvjdQAEh1ogWrVqpVQq6R6VmJjIVPertLQ0Dw+PQ4cOMQAKktatWysUinQVohESrq6uVvtwCWJJAsHBwRERETExMaJBkB6RcdSvX58BUMBUqFDhxYsX0dHR8fHxdEck2yOFqlq1KrNWIEkCffv29fT01Ezx8fHp0qULA6CA6dOnDxmbZoqXl1fnzp2ZtQJJEqhWrVr58uU1UypVqhQSEsIAKGDIzGrVqqWZUrJkyRo1ajBrBZKUweeff+7t7S0uFylS5NNPP2UAGARy0v38/MRlNzc3K3fPIUkZlC1blnwl9TJ5SQwAg0B61LBhQ3HodlBQ0AcffMCsGEjSG3r16uXr60u3qW7dujEADEiPHj0CAgKcnJzgnucyCODwxqeh15LlqbxCwXKEdsLluJrn2Ls/v0NlzM/TP7lvnmPxhTrKYXvtbTlVwlvtVjPnW6/Kfm8cn5eNpFImlTGvQJt2Q4KYaXPjVNTp/dFpybwiPZdfmHu95WKnue+BU5nyOx8il/3nbKk5WFrO5pR9mbPfSvfP0JlfdX1wmfJkvWpkUiaRMd8guzaDA1j25CRJRzdH3LmQEFzeJaSas0Rm8/p4WqYvHF51ZJ7jNYvLCd9171m1yZvfm7FVhmTp2ITOkkQlapmOrjp7rw+qfOPwqYuhLoPmKXldXxkH5LU3ybwH8XC86t+MQvKaexPKIJiR5rZvSigWQCxn1mrRfVBe3MXrkmepES7juFnQrAHN35vdiUhnD/+LuXcpzsFR1v37YGaqPP4vYc+KiKLF7ErVcHVxc1BmqrzXhiQYCZ9Rd2+MUNMgVcuqaydL/fOvTxunuYnGotr0Ml/eGXm0Tqv29a/Kob0r7StdnT/TmVVdDVrnTsI4pealp+R4icbXLGVQH1UtdMIH7UKieXSNGtOwc06oqsw/k73lHZeXqAqXxfDI5O7E3rsY6+xq8+moIJYN2UrSprmPYmPkXUeVZMCi2f1LaEqist/kEsz0OL494taZhO5jYIQWxa7FofIUZZ9Juk1Odywp/GHCq2fQI6ugzaBi6en8kc1Pmelx63TC+60LMWBZfDKkWFoqf2JnhM61uiXp7J/RDq54HbC1ULiofditVGZiXDr2itoFJStCkiwQDx+70GspOlfplqSUeIXMJucgHrAcXDxs5Wl5jacXODEv0qW4LVoozm6ytDSlzlW6ZwJIS2W8EpJkLSjlvDzF5CSJ+tfkqTBCyyQ9nUvPxuQwOQkQumMwwyowESBJAAATQrckCQOfcNu0GniemeCsWRL4bhZNdu8+0B3e5nnM7GZFcBLOBKeiV5qkUAL9IJxcxJJANvBKplAyAAxH9v4vJAkID8WYYguJWm54Ktz6gCSBjKewTA5qucF3s1Syf0ZctyRJZBxLR2jRWuBzfYAeAL3CSQQnWCe6JYmCC4hvWw8YlwQMTA6dvNn0uCmhSFaE0G4zPUnCIADrBLEkwDjGm2DLTclzStwXrQ9IEjDRoZKMmWQ/INAHQidvNmdXd8NNnDqRmQOftGu8es1yBiwOiTCA05iilJ1pweT0QHZzzmYbS+J4U36ipF2Hpk+fhYvLXTr3rFihCgMWh1LJK43actM0LZicfsmY01kX5tdwi4h4FhMTrf7aretnDOQPTsJxGJSYBbVpweQMid4kqW37Jn0+GxQbG7Nq9VIHB4ca1Wt/MXRU4cJFmDA3SvqK3xafPvPPixcR5ctXbvdJ51q16olb3bx5bcFPM5+EP65QoUqvHv1/WfpT8WIlhw8bTav+/ffvo38duHrtUlxcbNky5Xv27F+lcvVLl8+PGDmI1nbv8Undug2mTp5LXnSH9l3Lli3/7XdfLPxpRfnyGe9fu3X7xpChvWdM/6nW+3Vv3LhKpbp9+4abu0ftWh/07jXAyckp55+zbfvG9Rt+p5JMmPht27advxw6Kirq1eIl867fuJKSklKjRm0qbUCAMKU59U1u277hwIE9YU8eBQUWq169Vt8+g6VS6eYta9dvWDlqxLh5C6aTQRct6k+bfPRRK3H/jx8/pB9+5+4tqVQWHFz8s94D6ddR+o6dm9esXb5g3tIJk759+PBB8eIlO3Xs3rzZx7QqPiH+95W/nDn9T3RMVOmQ95o0adGqZVtxb/sP/LH7j22hofeKFSv5YaOPqEK4vHVWmWIzXZJ3R33s+BE2MpugoGIbN61WKpVkS9+M+qFkyYy3FlNr68DBPZGRL7y8fCpXqkYnV6J6tI/OBVXs5SsX6FSWK1fx0869KlSozFQNNKpJWjaMyZGlkdl4e/tS4SdNnFX/gw8t2+Syy51NLCm3lyllxcbGZtOm1XSOd+44sur3bdeuX1656ldx1f8Wztq6bX27tl3Wr/ujQf3G9MuPnzhC6VTRY8YN9/Ao9Nvyzf36Dvl5ybyXL5+LP4xWTZsxLjU19fvvJk2ftiAwMHjsuOF0hqgSZ0xbQBnWrd1FxqE+etUqNVycXU78fVSd8s8/f1FKjeq1noSHjfp2SEpqyqKFv0+ZNOfBg7vDRwwglcz559ja2iYlJe7evXX095NJQxUKxfCRA8lqhw8b89vyTR7uhcj4wp8+oZzbt29cu+63jh26bVy/5+OPO+zdt5NMiglvJZIlJiYcObp/3ZpdVCeNP2w2c9bEsLBHtCo6OuqLL/vQhbH01/U/L/yd9jZl6pikpCSxGhMS4qnGvhk5/ujhcw3qN5k1e/Lz58IsxbNmTbp54+qwYaNX/raVrof5C2aQ3VP64SP7f5w1KaRUmfVrd/fvN5SqetHiuSwvqIahMVODF17IkTdkUhndtGhh/76Tq1ZuK1S4yLgfRihUL/yiS2vnrs2DBw7buuUAGdux44e2bF1H6WlpacNGDKDr+ceZC+fOXkJ7IEsj81Pv02AmR6f+Qeg9+ps2ZR41DC3b5BjLYyyJ8r9DZNHPL6BH9750Vsg5Ii/pzp1blEiyQrcm8nXbfNzBzdWtZYtPGn/YfPWaZbSK/CbyqgYO+NrHx5d+3uf9vxArgrC3t1++dOPIEWPJIOhv0MBhycnJJHPZHZpMqlGjj078fUSdQrbSuHFzSj98+E+6c5JlkK7RzWHUyPF37/33z8ljOf8WUkayy08/7d2kcXN//8Br1y7TTWbM6Cnv16xTqFDhwYOGubq5b9u2nnJeuXqxdOn3mjVr7e7u0bpVu58XrXy/Zl1xJ2SF7dt9Sj6jq4sr3ZScHJ2OHD1A6XQx2NrZjRo5rqivH+2c7uTJyUm7dm8Rt5LL5XRTfe+9ClSGZh+1pnvDvXv/iQeqX78xWbyXl/eAz7+kAxUu7Enp+/btrFixyrCvvydxp+ukT+9BO3duJhNkb42JDpXk2DsYYVpaas8e/anqqG7JbSeLonNHd/sNG1dRer16Dck+GzZoQjfItetWUFXTFUt1RTd5ssASJUpN+GF/yc17AAAQAElEQVTmpEmzc5UPVjAmFxHxdNKEWXXq1CdbsmyTywFJdrXD8k5ISFn1souLKwk2LZAw0Y2IFEq9inzmBw/uxcbFktfn7OxMjqKYTtJDW6mzkZOycNHsjp2bN2pcvUUroaGn2Z7PSsOGTcn+7ty9TcuhofefPHlM2kfLN25cKVOmnJubu5iN5I8cWmoPsregTOly4gKpId1MqPbFr1Q/9CvohNEy+e0XLpyhGwu5svSj/Ir6q1sKmnUiXCRF/R8/DqVluhOWKlVGJstoNZNLH+AfJCp4xnHLlFNXI33STYw+qQVBnvmSXxacOnWCbKh0SFn6LdQ8Icdes3qrVKlBiW/5A0VMcxCAMF437+FtakeoK9bfL5A+Hz0OJd2hGqP7vDobnZeEhITw8DC6PunCJm+C/I7r16+Qm092SGb5NsfSu8lRK4xuxuKyZZtcDuiOJSmF0dt5ViWdQib+ti+/7pcpPTrqFd27HB21GthkHOICnemvh/evWqXm+LHTRfFu2qwWyxE6YaTZJ04codvd3//85enpJTbyqQC3/7tJupbp6OwtoOab+lfQKcm0E7G05D/Trzh56ji5snTKyUwHfv5VkSKeYh47Ozt1fjt7e1Gmo15FkkepuSt7B4ek5CT1V501+d23E6khSfE1shJnJ+d27br06vk53RWpYBSqoz+tH5gnL0nKW0x4297O/s2y6vKmOo+Kisy0ysHBkT7JU6AT9NP8ZdT2odYH1SFdw5/1GtC0acu3OZbeTc5Ww1os2+RyoMB73AqraoqaYJlqhJq1ZCLkQGkmvnr1Ulygpj6tokASuaAsN/9IhOqUHGlyj6lxS636pk0yrIoCCiT25MNrZnZzdWd5gZqiVJJpU+drJkolwgs06L5KzjP9UWjw4sWzK1cvJSOY/jpnYmKiOq6ZmpJCbXhacHRyokCD5q6Sk5LEW3oOkCtO7eLu3frQzZwugDVrVzg7u3Tu1MPR0fGjpq3IwdbMXNTXn709PGeC4e13a06KV6CIGBKys7N3chK8nuSUZPUq8sHps1AhofuFmlfULCILodP35/7d02f+EBRcnFQm12PB5DQz583kGJ/d9BMFLkn0s0XZFsP7TKWm5IPRryKRIq2hoDU1lSmdApNivI2gXjZyIEU9IsRweK582PAjivydPv0PNd2pES4mlihe6uChvZUqVpW8njmRTiS56ywvlCgRQsEsklFyksWUp8/C3d2EWxZ1fJCrXKxYCYoa0B+5fnv37VBveOnyuXp1GzJVTO1x2MPatT+gZeq8oPga3WrIMxd+bHwcNS7UPSM6If/8yJH9FImjOz+ZO/1Ra19sMlDZ6KDq6qXdPnsWTo1/9taYZnibsXcp1f0HdylAKTaaxIYJRQaoiijEQ+2psq+bJ7duXaegEvk1FK+5cfNqi+ZtqGIpiPP++3Wbt6xLG76NJDGYnIp3MDnhdpNNgDu70dtMqaf7JkkPhdkonk3hOnJ8SFyoM4I6I2lVrffrkaFQwIh0nTop1qxZTiYiblW8eKlXryKpl5G8xDNnT9GtgIzsxQsh+B0QGEyfx44dunnreqZjUQ8u1Qv1rZAV0qkSEzt27E4NXeoRoHsmxRR+Xfq/vv27UNOa5YVqVWvWrFlnzpwp1KIki9+5a8ugwT33799Nq6iD44eJ31Bjm04hmebf/xwtXy6jV5gskuyVjJ56T377fQmZiBhroF4Suq3NnTeN9kbGOmPmD+QwtmzRNocCUE8QdSpPnPwd3a9IxA8e3Hv33u0K5YW+6s/7fXHy5LF9f+6in0mVPHnK6BGjBmVyP80RYf4KaZ7dJFdXN+o8okuO/sjqvL19qPeK7vbkwlC0iE4TpVPt7di5iQyDThDd/CgoQ+ESskAyj3XrfyeTU59BEZic3k0uz0MlyZGX6O8Bo0+79CJZXb9xJSkLudDl3qs4cuQ4pnJNhw8bTS3SDp0+otgbxfxJnmQyQcWp//LRowdkUtTvSAF/atNSN+f6DSvj4+NGDB/TvNnHZAR0GubP+zXTsRo2aErtXnKk1SlkjiuWb9q4cdXAwT3oVFEY75tR49/yHqgJ9QSTRE6eOvrmzWsBAUFNmrRo3/5TJrRJxy36ec7Y8SOY0BAoTO50p449xE3oRkBeLp0tklfy+L7/dqI4rsTfL4B6dkiCP+3WmqSWwq4/LVie87gVWjt54uyFP88Wo3J0h6ReSLq3M1UMcukv6+haItNPSUmm6p06ZZ5mQCFXTLPHTamgvzzfF4sXI2ko0blLC7oafX2KTp08T6p6QeXQISPpcp0ybQwpDgWMunXt0/XT3kwVKiaLWrnqVzIb+lq92vvz5v6iFhcR8lNgcvo1uRzQPf5o1ZSHvJLrMCyIFTDhT59QA81VFeSnkrRu06DvZ4M7dOjKzJ9t2zcuXjLvyKGzzOT5Z9eL0GtxQ2aXZKbE4Q3P75xP6PlDibffZMLEbykqPHfOEmaVmJHJ/bU5IvxO4uDZOk6uMR8oIXd0yNDeJUuE9Os3lHouVqz4WcJJqPuAAQMjTClrcm6SxCRncQJ6wwSfcSMHcub0n5YtX/TDhFFpqankTKrGYhVhBmH02GHXr+kee9myZVvqgmFWA0VtTLDhJoxDsaz5kmByagR7y8bkdDfc1kx7TC359l/nrY/AvKDePYVSoXOVjcxGPWLNGvhnx/PQawlD5uahiWQADq9/fudC3hpuJg5MTk2eG27mMllSfqCuQAZUmObJtrxZbmFybwPm3gZMapINNw6xJKsEE90CpjTRoZK8BO8DsD4gScBEEboB8T4AC0U197bu+43uhpswDh73J2BU8NIkC0boTc3GM89uJgC8/9SKkEg5qQ0zNXhmok/egQIFDTcgPLehkDOT452mcAPmDiQJmCi8ErEkawSSBEwUOEjWie7wto2tRCLDDcpakEpN8XRzEk6CO6aFIpWx7EwuO0kSvGYGrIOkxFSZLTM17Jx5zsIecgOvSUlMs7HLyyCAYpWcUuJgDdZCdIS8SFGTe8Cqbmvv9HSWnGz2c9GBrMS+VHj66TY53ZJU/cMiNjbs0NpHDFg6YXdjUhIVbQfnaeJkA1HEz2bfr2EMWBb/XYhMS1Z8/LmfzrU5vUJy+fj7do6s7RDLeRQbZOLvHc8eXk/sPyXQ1sH0Wm4q/lga/uxhcou+fu6eDgyYPye2PX18K2nAzGLibJ9ZyeWttqumPEiMVUqkTJGuu+HHcVrj2bjXQyw10znttxFwXLZTDWTdG1PvUNfgTXX+TBu+2fz1sbP7kTo3FDdQb56HDXMsVU5fsxQx1/1nfGrUrVad51gzTHjHKS+XMzsH1ueHYlJb3cZhImxd8OjFE7lUxvEKXqFrqjkuy+suVL9aeGRBp1VkrXWddsu/tkCNbFnfqyHkkkhUo4vFPKoDZ8qTqSRv9qzao+bm2usFJByvVM86LZ54dTkp1vZmQuo3W3Gc5kvP3qRLJZxCyXPaF4W26WnsRMevfv1D3hyX5zLeW5uxoUQYvMFpXuPq/UhteF7BbBy4/pNz8nJyf9F2WnLaxROxaQnZ7kH7YtL5S3ntLl2tiswRnfbztmgcNftttYsWHv40ISGhdOkQ1RqOy/MReS7jWJmMOdcNs/Z5Z7vt64KpD6Rb3nM+tNSWFa/o5BtkNtNlXDgSmRD79pO6vZbtLJWQzWnVdcpeX/+6z4/Wdppb6cyb6cJX75l7XSL+5cvIiIiIChXKs+x5s51qQ83f8tr2sm7y5mkynhP0LUuJdJuKeueae9a2PV2bZ3yjf5RiRaj3I7Plild28gnIxdvNvZeVXPpazTyZdbBx45GY1LD6HeoyYGJUa2yg6UaNxaFDl889PDK0QyNm3WDghxbp6enqlxQDYEhgeyKoAi1gFsBYwPZEUAVaqF8HCoCBge2JSBjQAGYBjAW8JBFIkhYwC2AsYHsiqAItYBbAWMD2RFAFWsAsgLFA0EAEl58WkCRgLGB7IoglaQGzAMYCtieCKtACZgGMBWxPBFWgBcwCGAvYngiqQAuEGIGxgO2JQJK0wJ0KGAvYngiqQAuYBTAWsD0RVIEWMAtgLGB7IqgCLdCeB8YCticCSdICdypgLGB7IqgCLWAWwFjA9kRQBVrALICxgO2JoAq0gFkAYwHbE0EVaIEQIzAWkCQRVIEWMAtgLGB7IpgJQAsvL69jx44xAAzLmTNn6NPNzY1ZPbm/WtKqiI6OXrhw4Z49e9q3b9+hQ4dSpUoxAAqM5OTkbdu2bdmyxc/Pb9CgQRUrVmRWDyRJBwqFYvv27WQrdnZ2JExt2rRhAOiVy5cvk4H99ddfZGCdOnXy9/dnQAUkKSeuX79OdrNv3z7RaSpZsiQDIB/Q3W6bCmdnZ7Koli1bMqANJCl3KO4oOk2Ojo5kRq1bt2YA5JHbt29v3bp19+7dHVTg9pYdkKQ8cPXqVRKmAwcOiE5TiRIlGAC5sWvXLjIb8o86duzYrl07BnIEkpRn5HK56DSJvnerVq0YAFkIDQ2luDXZCVkI2Um5cuUYeAsgSe/OlStXyOAOHz5Mtz6yueLFizMAGCM/mtpo1HtLcWsyDIw2yhOQpPySmpq6Y8cO0iZXV1dq0MFpslrCw8PF0HXdunWpjVa1alUG8g4kSW9Qty416I4cOSJGmoKDgxmwDo4dO0ZttLCwMDF0TS16Bt4VSJKeSUlJESNNHh4eZJ0tWrRgwEKJjIwU3aIKFSpQG61WrVoM5BtIUkFx6dIlMla6f7ZXAafJkjh16hRFi27cuCG6RYULF2ZAT0CSCpbk5OTtKshqSZiaN2/OgNmSkJAgPv9RrFgxihY1aNCAAX0DSTIQFy5cIGE6ceKEGGkKDAxkwHyg00didPLkSfH5D19fXwYKBkiSQUlKShIjTV5eXqRNzZo1Y8CESUtLo5NFbTRyckmMcL4MACTJOKjvuuKYpoCAAAZMCfHxxv3799PZoTYaQoEGA5JkTCg2IY5p8vHxIafpo48+YsDYiG6sTCbDJBBGAZJkEpw7d46uBOrHocuAtAlTVRieu3fvUgONxEj0W8uUKcOAMYAkmRBihw5pU9GiRemqaNKkCQMFz969e6naKcxHDTSqdo7jGDAekCRT5OzZs3SR0Kd4x/bz82NA3zx+/Fh0ixo3bkyVXKlSJQZMAEiS6RIXFydGmqgdR9cMXTkM6IPDhw+TGD1//lx0i+zt7RkwGSBJZsCZM2dImM6fPy8OBKdmHQN5hzRIfP6jevXqJEY1atRgwPSAJJkNsbGx4kDwwMBAurd/+OGHDLwdf//9N7lFFMAWn/9wd3dnwFSBJJkfp0+fplv9xYsXxYHgPj4+mmup31oqla5Zs8aqnkcfOnTohQsXqGY0E2NiYsRoUenSpcktqlevHgMmDyTJXKHrTRxBU7x4cdKmRo0aienUKqFzShfh+vXrmXUwYcKEAwcOpKWlkUyLKWJTl76KbpGXlxcDZgIkyew5deoUadPly5fFJzqsYwAACA5JREFUSFPLli0lEgmd1vfff3/x4sVZ8587GPn4dnLsq3R5mpJXMIVCSKSObzIEqYQplG9ycoJ1cIz6xFU2wkkYr3yTWVjIWJORwqnyKFV5hC1f96ar8xMSjilfL6t2/6bHXb1/EWEuRo5JbThHF6lPkN2HXXyYLn7++ecNGzakpKTQcqFChXr27EliJI6iQIeAOQJJshCio6NJmEiD1EIgk8nIdZoxY4b49dGt+OPbIuOiFbReZiO1sZfK7GUSG6lUUBJBCzjhzcdkDBxJhkS1D6Xqbci8SnqEdYLI8KoFJh4kUwqv+icjsypBPLSS8ZKMfbzZmwq1pomrRP3LQEH7UyoVKelpSelyuYJPZ3ZOrGxN13pt3rg81C6jn0xdkxmbKBS9e/emNhrGmpovkCSLolq1apoj/WxtbclvGjVq1O+THiTFKe2cbbxLebgUdmLmycPLzxJfpdDvq/Nxocr1Cx0/fpwENzIyUjOPn5/frl27GDBbIEmWw0cffRQVFaWZolQqPygzuJR3A0cPh+I1LGToQPitF9HhifZOii1nvnr58iWlUENVvZaWz549y4DZAkmyHCiwTb1sdnZ25CjRlUkuUu2AUU62XiH1A2iZWRZ3Tz1JTIg//3ImhfmpvUY/WS6Xp6amJiUlnT9/ngGzBZJkUVCom1TJ3d3d1dX17N6Uu5cTyn1YjFkooZci0hNTP59WnGLb8fHxFFGKjY3Fe0HMHUiSZbJ+9iPqUyvbIJhZNGHXnie+Sh70I147bDlIGLA4Dq1/FvNCbvF6RARU8LZ1lK0YH8qApQBJskD+O5dYuoG1zO1dvKZ/SpLi4LqnDFgEkCRLY9nYBw6utlKplFkNRSsWuXM+iQGLAJJkUTy8GZuWrCxRy7rmV/LwcpHYcFsXPGbA/IEkWRR/bX5l62TDTJVtf8yavbArKwA8i7tHPEpjwPyBJFkUibFK39KFmPXhGSTMN3Jm/0sGzBxIkuVw9kAk45hzYUdmlVDXG8X1GTBzZAxYCg+uJXAFGdQ+d3HPv+d2PHt+z9e7ZOUKTT6o/an4PN2aTWMY46pWar5p++TU1KSggAqtmn0RFFCeVtHXdVt/uPfgPG1Su0Z7VpA4etglvECQ2+yBl2Q5JMQo7J0L6sGRi1cObNoxxb9o6TEjdrRoOvjEqY279s0XV0kkskdh1y5c/vPrQSun/3BcZmO7cftkcdXmndMiX4UN/GxR764/Rrx4cPvOSVZguHg7KJQY92v2QJIsh/Q03tahoGLbZy/sKh5Upf3H37o4FypVvHqzxgNOntkSn5DxlC95Q13ajStcyE8qlVWt2Oxl5CNKiY17eeX64Ub1epLH5OpSuHWzL2xkBTjxvlsRF17B8DSCuQNJshzIRZDaFkjLTalUhj6+GlLqfXUKqRLPK0MfXha/enkG29llxLDs7V3oMyk5Lio6nBa8vd48ZBfgV5YVKBx7+VTOgDmDWJLlIOEK6onF9PQ0hUK+//Av9KeZHp+Y4SVxnI57W2JSLH3a2b4Jt9vaOrACxkamZMCcgSRZDhIbTpGqYAWAra09KUu1yi0rltN6LQq11HLYysnRjT7T5CnqlJTUAuwRS0tLYzzz8MZL2cwbSJLlYOcokSens4KhqG9Ickp8yeLVxK/p6fJX0eHubt45bOLhLkwa9/DxVbG9RpvcvX/WycmDFQyJkSkSK3qKxmJBLMlycPe0kacWlCS1bDr4+q3jZy7sFuJKjy6v3Tz219+HUoMuh03c3byCAysdOLr0xctHcnnqui3jmcYkvHon7kWyzBb2bPbgFFoO5Wu5KOQFFUkpFlR5+ODVFM+e+GPzX1d+mZyS0Kf7bBsbu5y36tphQqB/uQVLeo2d2sjRwbVm1TaswHrEkmNTCvma7sM04C3BFG4WxeJR9woHu3mXsMZnSq4fDP14sE9QiBW9UNMigZdkUXgH2cU8TWDWx+PrL2R2DHpkASC8bVF0+DJg0fB7yQmpDs66m1SXrh7c9sePOldRwyopOU7nqverffJx86+YnqBQ1Iq1I3WuUioVHCfhdIWcGtXr2bjBZywb4p8nlq/jyoD5g4abpbH957AX4fIyHwTpXJuampSYFJPNqmQ7O93jhmxtHZ2d3Jn+iIrO8ySQDvYuDg4uOlc9ufYiMTpp4AzMwG0JQJIskF++u+/u7+JTsjCzDq4fCu00vKh3gJVOgWBhIJZkgXz6jX9kaByzDm4fe1SsnAP0yGKAJFkg7kXsGnQofOOw5b+34+bRUHdPWat+1jWxr2WDhpvFEh+VtmrK45AP/GwdLO1VtyL/nXhUtqZz/XZeDFgQkCRL5vbZmCMbI5297IMq+TILIios7tmdV75Bdu2/DGDAsoAkWT7Lxz1IS+UL+Tn7lC7CzJz4V4nh118p5Ip6bQtX+qCgHpcDRgSSZBX8teX57XPxPM/ZOdkWCnLx8HFhZkVyfPLz+3FJUcnKdN470LbTcGt5caYVAkmyIk7vi7x9Pj4xVpjARCLlOKmE41m2c8NyjPGa3ygvnykxa04hm/BVOyfHZUrhOE5Y5LUOIKCRIJUwJSUolSRDvJLZ2HL+IQ6t+hVlwKKBJFkjj+8k3L+SGB8tT0tmaak6ntTlVP9rKYZqfrhMiiR+5TRyCgOvOUFBOAmpiTpRpUjqbLQsFb5o7V+SOUVmJ7W15R2cZf4h9uXe1+dATWDKQJIAACYEnnEDAJgQkCQAgAkBSQIAmBCQJACACQFJAgCYEJAkAIAJ8X8AAAD//03G7e4AAAAGSURBVAMAYgUtZTx0WTUAAAAASUVORK5CYII=",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000020C113CEC50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph=StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node(\"sentiment_node\",find_sentiment)\n",
    "graph.add_node(\"positive_response\",positive_response)\n",
    "graph.add_node(\"negative_response\",negative_response)\n",
    "graph.add_node(\"run_diagnosis\",run_diagnosis)\n",
    "\n",
    "graph.add_edge(START,'sentiment_node')\n",
    "graph.add_conditional_edges('sentiment_node',check_sentiment)\n",
    "graph.add_edge('positive_response', END)\n",
    "\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "\n",
    "\n",
    "workflow=graph.compile()\n",
    "\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b38c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'issue_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m intial_state\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m }\n\u001b[1;32m----> 4\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3068\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3069\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3071\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3072\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3073\u001b[0m     config,\n\u001b[0;32m   3074\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3075\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3076\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3077\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3078\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3079\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3080\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3081\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3082\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3083\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3084\u001b[0m ):\n\u001b[0;32m   3085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3086\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2645\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2646\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2647\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2648\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2649\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2650\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2651\u001b[0m ):\n\u001b[0;32m   2652\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2653\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2654\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2655\u001b[0m     )\n\u001b[0;32m   2656\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 656\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\Data Science\\langgraph_tutorials\\myenv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 400\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[42], line 25\u001b[0m, in \u001b[0;36mnegative_response\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnegative_response\u001b[39m(state:ReviewState):\n\u001b[0;32m     22\u001b[0m     diagnosis \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     24\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a support assistant.\u001b[39m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;124m    The user had a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiagnosis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m issue, sounded \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiagnosis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtone\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, and marked urgency as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiagnosis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murgency\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m    Write an empathetic, helpful resolution message.\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     response\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minvoke(prompt)\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m:response}\n",
      "\u001b[1;31mKeyError\u001b[0m: 'issue_type'"
     ]
    }
   ],
   "source": [
    "intial_state={\n",
    "    'review': \"Ive been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\"\n",
    "}\n",
    "workflow.invoke(intial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
