{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "923d4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "764013e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # take environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c25f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f92f765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogState(TypedDict):\n",
    "    topic: str\n",
    "    outline: str\n",
    "    blog_post: str\n",
    "    score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68e58a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outline(state:BlogState)->BlogState:\n",
    "    topic=state['topic']\n",
    "    prompt=f\"Generate a detailed outline for a blog post about the following topic:\\n{topic}\"\n",
    "    response=model.invoke([{\"role\":\"user\",\"content\":prompt}])\n",
    "    state['outline']=response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b9d3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_blog_post(state:BlogState)->BlogState:\n",
    "    outline=state['outline']\n",
    "    prompt=f\"Write a blog post based on the following outline:\\n{outline}\"\n",
    "    response=model.invoke([{\"role\":\"user\",\"content\":prompt}])\n",
    "    state['blog_post']=response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b50f91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_blog_post(state:BlogState)->BlogState:\n",
    "    blog_post=state['blog_post']\n",
    "    prompt=f\"Score the following blog post on a scale of 1 to 10 and return only the score, based on outline adherence:\\n{blog_post}\"\n",
    "    response=model.invoke([{\"role\":\"user\",\"content\":prompt}])\n",
    "    state['score']=int(response.content)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a72332ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(BlogState)\n",
    "\n",
    "\n",
    "graph.add_node('generate_outline',generate_outline)\n",
    "graph.add_node('write_blog_post',write_blog_post)\n",
    "graph.add_node('score_blog_post',score_blog_post) \n",
    "\n",
    "\n",
    "graph.add_edge(START,'generate_outline')\n",
    "graph.add_edge('generate_outline','write_blog_post')\n",
    "graph.add_edge('write_blog_post','score_blog_post')\n",
    "graph.add_edge('score_blog_post',END)\n",
    "\n",
    "\n",
    "\n",
    "workflow=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08c4e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Supercharge Your LLM Applications: The Transformative Benefits of LangGraph\n",
      "\n",
      "Are you hitting the ceiling with simple LLM prompts and basic chains? Do your LLM applications struggle with multi-step reasoning, self-correction, or maintaining context over time? As the demand for sophisticated AI grows, the need for more resilient, stateful, and truly intelligent LLM applications becomes paramount. We're moving beyond mere text generation to building AI agents that can perform complex tasks, utilize tools, and adapt to dynamic situations.\n",
      "\n",
      "Enter LangGraph. Built on top of the popular LangChain framework, LangGraph is a powerful library designed specifically for building stateful, multi-actor applications with LLMs. It addresses the limitations of stateless interactions by enabling the creation of dynamic, graph-based workflows. This post will dive into the key **benefits of adopting LangGraph**, demonstrating how it empowers developers to create truly intelligent and robust LLM workflows, unlocking the next generation of **agentic AI**.\n",
      "\n",
      "### What is LangGraph? A Quick Primer\n",
      "\n",
      "At its core, LangGraph allows you to define workflows as directed acyclic or, crucially, *cyclical* graphs – essentially, state machines for your LLM applications.\n",
      "\n",
      "It operates with a few key components:\n",
      "*   **Nodes:** These represent individual steps or actions within your workflow. A node could be an LLM call, a tool invocation (like a search engine or database query), a human input, or even a conditional check.\n",
      "*   **Edges:** These define the transitions between nodes. Edges dictate where the workflow goes next, often based on conditions or the output of the preceding node.\n",
      "*   **State:** This is LangGraph's superpower. It allows for a shared, mutable state that evolves as the graph executes. This state acts as the application's memory, enabling context persistence and multi-turn interactions.\n",
      "\n",
      "While LangChain provides powerful chains for sequential operations, LangGraph extends this by explicitly managing state and introducing the ability to create cycles. These cycles are fundamental for implementing advanced decision-making, retries, and **self-correction** – all hallmarks of true **agentic behavior**.\n",
      "\n",
      "### The Transformative Benefits of LangGraph\n",
      "\n",
      "LangGraph isn't just another library; it's a paradigm shift for **LLM workflows**. Here's how it transforms your development process:\n",
      "\n",
      "#### 1. Enabling Complex, Stateful Workflows\n",
      "\n",
      "LangGraph inherently manages and updates state across multiple steps, allowing your applications to \"remember\" context and progress through complex interactions. Unlike stateless API calls or simple chains that require explicit context passing at every turn, LangGraph's shared state simplifies the development of sophisticated, multi-turn interactions, personalized experiences, and long-running processes. Imagine a multi-step customer support agent that not only tracks conversation history but also remembers user preferences and past interactions to provide truly personalized assistance.\n",
      "\n",
      "#### 2. Robustness and Self-Correction (Agentic Behavior)\n",
      "\n",
      "The power of cyclical graphs is monumental for building **robust** applications. LangGraph allows you to implement decision-making, retry mechanisms, and **self-correction** loops. An LLM can decide which path to take next, re-evaluate its output, or even call a \"critic\" node to improve its answer before presenting it. This leads to more reliable applications that can recover from errors, refine their outputs, and exhibit true **agentic intelligence**. A prime example is a code generation agent that writes code, runs tests, and then debugs itself if tests fail, iterating until the code passes.\n",
      "\n",
      "#### 3. Enhanced Observability and Debugging\n",
      "\n",
      "The explicit graph structure provides a clear, often visual, representation of your workflow. When integrated with tools like LangSmith, the execution paths become transparent. This means you can easily trace the exact sequence of LLM calls, tool uses, and conditional branches that led to an answer (or an incorrect one). This dramatically reduces the \"black box\" syndrome often associated with LLMs, making it easier to understand how your **AI applications** reach a conclusion, pinpoint errors, and optimize performance.\n",
      "\n",
      "#### 4. Modularity and Reusability\n",
      "\n",
      "With LangGraph, each node can be a self-contained unit – an LLM call, a tool, or even a sub-graph. This promotes cleaner code, easier maintenance, and the ability to reuse components across different workflows or even different parts of the same complex workflow. This modularity accelerates development significantly. For instance, a \"search_tool\" node that queries an external API can be dropped into any agent needing external information retrieval, without needing to rewrite its logic.\n",
      "\n",
      "#### 5. Seamless Tool Integration & Orchestration\n",
      "\n",
      "LangGraph is designed from the ground up to empower LLMs to use external tools effectively. The graph structure allows for the sophisticated orchestration of complex sequences of tool calls, enabling your LLM to interact with databases, APIs, code interpreters, and more. This extends the capabilities of LLMs far beyond simple text generation, allowing them to perform real-world actions. Consider a data analysis agent that plans a series of SQL queries, Python script executions, and visualization steps to generate a comprehensive report.\n",
      "\n",
      "#### 6. Human-in-the-Loop Capabilities\n",
      "\n",
      "For sensitive applications or those requiring expert oversight, LangGraph allows the graph to pause execution at specific nodes, awaiting human input, validation, or override. This **human-in-the-loop** capability is critical for ensuring accuracy, compliance, and allowing for progressive disclosure or expert intervention when needed. An example could be a legal document generator that drafts a contract but pauses for human review and approval before finalizing the draft.\n",
      "\n",
      "### How LangGraph Works: A Simplified Walkthrough\n",
      "\n",
      "Think of building with LangGraph like designing an interactive flowchart for your LLM.\n",
      "\n",
      "1.  **Define Your State:** First, you define the data structure that represents your application's memory – what information needs to persist and evolve?\n",
      "2.  **Create Your Nodes:** Next, you implement the individual actions your LLM agent can take. These are your nodes, like an `llm_node` for making an LLM call, a `tool_node` for using an external tool, or a `human_input_node` for pausing for user input.\n",
      "3.  **Define Your Edges:** Then, you specify how the workflow transitions between these nodes. You use `add_edge` for direct transitions or `add_conditional_edges` for branching logic based on the output of a node or the current state.\n",
      "4.  **Compile and Invoke:** Finally, you compile your graph into a runnable object and invoke it with an initial state, setting your **LLM workflow** in motion.\n",
      "\n",
      "### Real-World Use Cases\n",
      "\n",
      "The potential of LangGraph for building **complex reasoning** and **robust AI applications** is vast:\n",
      "\n",
      "*   **Advanced Customer Support Agents:** Handling complex queries, escalating to human agents with full context, and providing personalized assistance based on user history.\n",
      "*   **Automated Research & Content Generation:** Agents that iteratively gather information from multiple sources, draft content, request revisions, and perform fact-checking in a loop.\n",
      "*   **Data Analysis & Visualization Assistants:** Planning and executing data queries, running scripts, generating charts, and interpreting results, all orchestrated through a graph.\n",
      "*   **Code Generation & Debugging:** Writing code, running tests, identifying errors, and suggesting fixes in a continuous feedback loop until the code is functional.\n",
      "*   **Interactive Learning Tutors:** Adapting to student responses, providing personalized feedback, and guiding learners through complex topics with adaptive paths.\n",
      "\n",
      "### Getting Started with LangGraph\n",
      "\n",
      "Ready to move **beyond simple prompts** and build smarter, more **agentic AI**? Getting started with LangGraph is straightforward. You can install it via pip: `pip install langgraph langchain`.\n",
      "\n",
      "From there, dive into the official LangGraph documentation and tutorials. They provide excellent examples to help you understand the core concepts and start building your own complex LLM applications. Join the vibrant LangChain/LangGraph community for support and inspiration as you embark on this exciting journey!\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "LangGraph is an indispensable tool for moving beyond basic LLM interactions to building truly intelligent, dynamic, and reliable **AI applications**. By embracing statefulness, enabling self-correction, enhancing observability, promoting modularity, facilitating seamless tool use, and integrating **human-in-the-loop** capabilities, LangGraph empowers developers to create **LLM workflows** that were previously challenging or impossible.\n",
      "\n",
      "It represents a critical step forward in the evolution of **LLM development**, positioning itself as a foundational component for building the next generation of **agentic AI**. If you're serious about creating sophisticated and powerful AI, LangGraph is your next workflow powerhouse.\n"
     ]
    }
   ],
   "source": [
    "initial_state={'topic': 'The benefits of using LangGraph for LLM workflows'}\n",
    "final_state=workflow.invoke(initial_state)\n",
    "print(final_state['blog_post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9b25934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(final_state['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16409c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a detailed outline for a blog post about the benefits of using LangGraph for LLM workflows, designed to be engaging, informative, and actionable.\n",
      "\n",
      "---\n",
      "\n",
      "## Blog Post Outline: Supercharge Your LLM Applications: The Transformative Benefits of LangGraph\n",
      "\n",
      "**Target Audience:** Developers, data scientists, AI engineers, product managers interested in building robust, complex, and agentic LLM-powered applications.\n",
      "\n",
      "---\n",
      "\n",
      "### I. Catchy Title Options:\n",
      "*   Supercharge Your LLM Applications: The Transformative Benefits of LangGraph\n",
      "*   Beyond Simple Prompts: Why LangGraph is Your Next LLM Workflow Powerhouse\n",
      "*   Unlock Agentic AI: The Essential Benefits of Using LangGraph for LLM Workflows\n",
      "*   Building Smarter LLM Apps: Discover the Power of LangGraph\n",
      "*   From Chains to Graphs: How LangGraph Elevates Your LLM Development\n",
      "\n",
      "### II. Introduction (Approx. 150-200 words)\n",
      "\n",
      "*   **A. Hook:** Start with the limitations of simple, stateless LLM API calls or basic prompt chaining. (e.g., \"Are you hitting the ceiling with simple LLM prompts and basic chains? Do your LLM applications struggle with multi-step reasoning, self-correction, or maintaining context over time?\")\n",
      "*   **B. Problem Statement:** Highlight the growing need for more sophisticated, stateful, and resilient LLM applications that can perform complex tasks, utilize tools, and adapt to dynamic situations.\n",
      "*   **C. Introduce LangGraph:** Present LangGraph as the solution. Briefly define it as a library for building stateful, multi-actor applications with LLMs, built on top of LangChain.\n",
      "*   **D. Thesis Statement:** State clearly that this post will dive into the key benefits of adopting LangGraph, demonstrating how it enables the creation of truly intelligent and robust LLM workflows.\n",
      "\n",
      "### III. What is LangGraph? A Quick Primer (Approx. 100-150 words)\n",
      "\n",
      "*   **A. Core Concept:** Explain LangGraph as a framework for defining workflows as directed acyclic or *cyclical* graphs (state machines).\n",
      "*   **B. Key Components:**\n",
      "    *   **Nodes:** Represent individual steps or actions (e.g., an LLM call, a tool invocation, a human input, a conditional check).\n",
      "    *   **Edges:** Define the transitions between nodes based on conditions or outcomes.\n",
      "    *   **State:** Crucially, LangGraph allows for shared, mutable state that evolves as the graph executes, enabling memory and context.\n",
      "*   **C. Distinction from LangChain Chains:** Emphasize that while LangChain provides powerful chains, LangGraph extends this by explicitly managing state and allowing for cycles, which are essential for agentic behavior.\n",
      "\n",
      "### IV. The Transformative Benefits of LangGraph (Core Section - Approx. 600-800 words, 6 distinct benefits)\n",
      "\n",
      "*   **A. Benefit 1: Enabling Complex, Stateful Workflows**\n",
      "    *   **Explanation:** How LangGraph inherently manages and updates state across multiple steps, allowing applications to \"remember\" context and progress.\n",
      "    *   **Contrast:** Unlike stateless API calls or simple chains that need explicit context passing.\n",
      "    *   **Impact:** Builds sophisticated, multi-turn interactions, personalized experiences, and long-running processes.\n",
      "    *   **Example:** A multi-step customer support agent that tracks conversation history and user preferences.\n",
      "\n",
      "*   **B. Benefit 2: Robustness and Self-Correction (Agentic Behavior)**\n",
      "    *   **Explanation:** The power of cyclical graphs to implement decision-making, retry mechanisms, and self-correction loops.\n",
      "    *   **How it works:** An LLM can decide which path to take next, re-evaluate its output, or even call a \"critic\" node to improve its answer.\n",
      "    *   **Impact:** More reliable applications that can recover from errors, refine their outputs, and exhibit true agentic intelligence.\n",
      "    *   **Example:** A code generation agent that writes code, runs tests, and then debugs itself if tests fail.\n",
      "\n",
      "*   **C. Benefit 3: Enhanced Observability and Debugging**\n",
      "    *   **Explanation:** The graph structure provides a clear, visual representation of the workflow. Integration with tools like LangSmith makes execution paths transparent.\n",
      "    *   **Impact:** Easier to understand how an LLM application reaches a conclusion, pinpoint errors, and optimize performance. Reduces \"black box\" syndrome.\n",
      "    *   **Example:** Tracing the exact sequence of LLM calls, tool uses, and conditional branches that led to an incorrect answer.\n",
      "\n",
      "*   **D. Benefit 4: Modularity and Reusability**\n",
      "    *   **Explanation:** Each node can be a self-contained unit (an LLM call, a tool, a sub-graph).\n",
      "    *   **Impact:** Promotes cleaner code, easier maintenance, and the ability to reuse components across different workflows or even different parts of the same complex workflow. Accelerates development.\n",
      "    *   **Example:** A \"search_tool\" node that can be dropped into any agent needing external information retrieval.\n",
      "\n",
      "*   **E. Benefit 5: Seamless Tool Integration & Orchestration**\n",
      "    *   **Explanation:** LangGraph is designed from the ground up to empower LLMs to use external tools effectively. The graph can orchestrate complex sequences of tool calls.\n",
      "    *   **Impact:** Extends the capabilities of LLMs far beyond text generation, allowing them to interact with databases, APIs, code interpreters, and more.\n",
      "    *   **Example:** A data analysis agent that plans a series of SQL queries, Python script executions, and visualization steps.\n",
      "\n",
      "*   **F. Benefit 6: Human-in-the-Loop Capabilities**\n",
      "    *   **Explanation:** The graph can pause execution at specific nodes, awaiting human input, validation, or override.\n",
      "    *   **Impact:** Critical for sensitive applications, ensuring accuracy, compliance, and allowing for progressive disclosure or expert intervention when needed.\n",
      "    *   **Example:** A legal document generator that pauses for human review before finalizing a draft.\n",
      "\n",
      "### V. How LangGraph Works: A Simplified Walkthrough (Approx. 150-200 words)\n",
      "\n",
      "*   **A. Define Your State:** Start by defining the data structure that represents your application's memory.\n",
      "*   **B. Create Your Nodes:** Implement the individual actions (e.g., `llm_node`, `tool_node`, `human_input_node`).\n",
      "*   **C. Define Your Edges:** Specify how the workflow transitions between nodes (e.g., `add_edge`, `add_conditional_edges`).\n",
      "*   **D. Compile and Invoke:** Build the `Graph` object and invoke it with an initial state.\n",
      "*   **E. Analogy:** Briefly compare it to building a flow chart or a state machine for your LLM.\n",
      "\n",
      "### VI. Real-World Use Cases (Approx. 150-200 words)\n",
      "\n",
      "*   **A. Advanced Customer Support Agents:** Handling complex queries, escalating to human agents, providing personalized assistance.\n",
      "*   **B. Automated Research & Content Generation:** Iteratively gathering information, drafting content, requesting revisions, and fact-checking.\n",
      "*   **C. Data Analysis & Visualization Assistants:** Planning and executing data queries, running scripts, generating charts, and interpreting results.\n",
      "*   **D. Code Generation & Debugging:** Writing code, running tests, identifying errors, and suggesting fixes in a loop.\n",
      "*   **E. Interactive Learning Tutors:** Adapting to student responses, providing personalized feedback, and guiding through complex topics.\n",
      "\n",
      "### VII. Getting Started with LangGraph (Call to Action - Approx. 75-100 words)\n",
      "\n",
      "*   **A. Installation:** Briefly mention `pip install langgraph langchain`.\n",
      "*   **B. First Steps:** Encourage readers to explore the official documentation and tutorials.\n",
      "*   **C. Invitation:** Invite them to start experimenting and building their own complex LLM applications.\n",
      "*   **D. Community:** Mention the LangChain/LangGraph community for support.\n",
      "\n",
      "### VIII. Conclusion (Approx. 100-150 words)\n",
      "\n",
      "*   **A. Recap:** Briefly summarize the key benefits discussed (statefulness, robustness, observability, modularity, tool use, human-in-the-loop).\n",
      "*   **B. Reinforce Value:** Reiterate that LangGraph is an indispensable tool for moving beyond basic LLM interactions to building truly intelligent, dynamic, and reliable AI applications.\n",
      "*   **C. Forward-Looking Statement:** End with a vision for the future of LLM development, positioning LangGraph as a critical component in building the next generation of AI agents.\n",
      "\n",
      "---\n",
      "\n",
      "**Tone:** Informative, enthusiastic, slightly technical but accessible, problem-solution oriented.\n",
      "\n",
      "**Keywords to Include:** LangGraph, LLM workflows, stateful, agentic AI, self-correction, observability, tool use, human-in-the-loop, LangChain, AI applications, complex reasoning, robust.\n"
     ]
    }
   ],
   "source": [
    "print(final_state['outline'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
